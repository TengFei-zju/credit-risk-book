# ç¬¬åå››ç«  å›¾æ¨¡å‹åœ¨é£æ§ä¸­çš„åº”ç”¨

## 14.1 å›¾æ¨¡å‹åœ¨é£æ§ä¸­çš„ä»·å€¼

### 14.1.1 ä¸ºä»€ä¹ˆéœ€è¦å›¾æ¨¡å‹

ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹å‡è®¾æ ·æœ¬ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆi.i.d.ï¼‰ï¼Œä½†ä¿¡è´·é£æ§ä¸­å­˜åœ¨å¤§é‡**å…³è”å…³ç³»**ï¼š

```
ä¼ ç»Ÿæ¨¡å‹å±€é™ï¼š
- åªåˆ©ç”¨ç”¨æˆ·è‡ªèº«ç‰¹å¾ï¼ˆå¹´é¾„ã€æ”¶å…¥ã€å¾ä¿¡...ï¼‰
- å¿½ç•¥ç”¨æˆ·ä¹‹é—´çš„å…³ç³»ï¼ˆæ‹…ä¿äººã€å…±åŒå€Ÿæ¬¾ã€è®¾å¤‡å…±äº«...ï¼‰
- æ— æ³•è¯†åˆ«å›¢ä¼™æ¬ºè¯ˆ

å›¾æ¨¡å‹ä¼˜åŠ¿ï¼š
- æ˜¾å¼å»ºæ¨¡ç”¨æˆ·é—´å…³ç³»
- æ•æ‰é£é™©ä¼ å¯¼è·¯å¾„
- è¯†åˆ«å¼‚å¸¸å­å›¾ï¼ˆæ¬ºè¯ˆå›¢ä¼™ï¼‰
```

### 14.1.2 é£æ§åœºæ™¯ä¸­çš„å›¾ç»“æ„

```
èŠ‚ç‚¹ï¼ˆNodesï¼‰ï¼š
â”œâ”€â”€ å€Ÿæ¬¾äººï¼ˆæ ¸å¿ƒèŠ‚ç‚¹ï¼‰
â”œâ”€â”€ æ‹…ä¿äºº/å…±åŒå€Ÿæ¬¾äºº
â”œâ”€â”€ è®¾å¤‡ï¼ˆæ‰‹æœºã€IP åœ°å€ï¼‰
â”œâ”€â”€ è”ç³»æ–¹å¼ï¼ˆæ‰‹æœºå·ã€é‚®ç®±ï¼‰
â””â”€â”€ åœ°å€ï¼ˆå®¶åº­åœ°å€ã€å…¬å¸åœ°å€ï¼‰

è¾¹ï¼ˆEdgesï¼‰ï¼š
â”œâ”€â”€ æ‹…ä¿å…³ç³»ï¼ˆå¼ºè¿æ¥ï¼‰
â”œâ”€â”€ å…±åŒå€Ÿæ¬¾ï¼ˆå¼ºè¿æ¥ï¼‰
â”œâ”€â”€ è®¾å¤‡å…±äº«ï¼ˆä¸­å¼ºè¿æ¥ï¼‰
â”œâ”€â”€ è”ç³»æ–¹å¼å…±äº«ï¼ˆä¸­å¼ºè¿æ¥ï¼‰
â””â”€â”€ åœ°å€å…±äº«ï¼ˆå¼±è¿æ¥ï¼‰
```

---

### 14.1.3 å›¾ç»“æ„å¯è§†åŒ–

#### å®¢æˆ·å…³ç³»å›¾è°±

![å®¢æˆ·å…³ç³»å›¾è°±](diagrams/ch14_customer_relationship_graph.drawio)

**å›¾ä¾‹è¯´æ˜**ï¼š
- ğŸ”´ çº¢è‰²èŠ‚ç‚¹ï¼šè¿çº¦å®¢æˆ·
- ğŸŸ¢ ç»¿è‰²èŠ‚ç‚¹ï¼šæ­£å¸¸å®¢æˆ·
- ğŸ”µ è“è‰²èŠ‚ç‚¹ï¼šè®¾å¤‡èŠ‚ç‚¹
- ğŸŸ¡ é»„è‰²èŠ‚ç‚¹ï¼šåœ°å€èŠ‚ç‚¹
- å®çº¿è¾¹ï¼šæ‹…ä¿å…³ç³»ï¼ˆå¼ºè¿æ¥ï¼‰
- è™šçº¿è¾¹ï¼šå…±äº«å…³ç³»ï¼ˆä¸­å¼±è¿æ¥ï¼‰

**é£é™©æ´å¯Ÿ**ï¼š
- ç”¨æˆ· Aã€C å‡è¿çº¦ï¼Œä¸”å…±ç”¨è®¾å¤‡ D1 â†’ å¯èƒ½å­˜åœ¨å›¢ä¼™æ¬ºè¯ˆ
- ç”¨æˆ· B ä¸è¿çº¦ç”¨æˆ· A æœ‰æ‹…ä¿å…³ç³»ï¼Œä¸”å…±ç”¨åŒä¸€è®¾å¤‡ â†’ é£é™©ä¼ å¯¼ä¿¡å·
- ç”¨æˆ· Dã€E å…±ç”¨åœ°å€ä½†æ— å…¶ä»–é£é™©ä¿¡å· â†’ éœ€ç»“åˆå…¶ä»–ç‰¹å¾åˆ¤æ–­

---

### 14.1.4 GCN æ¶ˆæ¯ä¼ é€’æœºåˆ¶

![GCN æ¶ˆæ¯ä¼ é€’ç¤ºæ„å›¾](diagrams/ch14_gcn_message_passing.drawio)

ä¸Šå›¾å±•ç¤ºäº†å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰çš„æ ¸å¿ƒæ“ä½œï¼š
1. ä¸­å¿ƒèŠ‚ç‚¹ A èšåˆé‚»å±… Bã€Cã€D çš„ç‰¹å¾
2. é€šè¿‡èšåˆå‡½æ•°ï¼ˆâŠ•ï¼‰ç”Ÿæˆæ–°çš„èŠ‚ç‚¹åµŒå…¥
3. è¾“å‡ºå±‚å°†åµŒå…¥æ˜ å°„ä¸ºè¿çº¦æ¦‚ç‡

---

## 14.2 å›¾ç‰¹å¾å·¥ç¨‹

### 14.2.1 åŸºç¡€å›¾ç‰¹å¾

```python
import networkx as nx
import pandas as pd

def build_customer_graph(loans_df, relations_df):
    """
    æ„å»ºå®¢æˆ·å…³ç³»å›¾
    loans_df: å€Ÿæ¬¾è®°å½•è¡¨ï¼ˆcustomer_id, loan_id, ...ï¼‰
    relations_df: å…³ç³»è¡¨ï¼ˆcustomer_id_1, customer_id_2, relation_typeï¼‰
    """
    G = nx.Graph()

    # æ·»åŠ èŠ‚ç‚¹ï¼ˆå®¢æˆ·ï¼‰
    customers = loans_df['customer_id'].unique()
    for c in customers:
        G.add_node(c, node_type='customer')

    # æ·»åŠ è¾¹ï¼ˆå…³ç³»ï¼‰
    for _, row in relations_df.iterrows():
        G.add_edge(
            row['customer_id_1'],
            row['customer_id_2'],
            relation_type=row['relation_type'],
            weight={'guarantor': 1.0, 'co_borrower': 0.8, 'device': 0.5}.get(
                row['relation_type'], 0.3
            )
        )

    return G


def extract_graph_features(G, customer_id):
    """
    æå–å®¢æˆ·çš„å›¾ç‰¹å¾
    """
    if customer_id not in G:
        return {}

    # 1. ä¸€åº¦é‚»å±…ç‰¹å¾
    neighbors = list(G.neighbors(customer_id))
    n_neighbors = len(neighbors)

    # 2. äºŒåº¦é‚»å±…ç‰¹å¾ï¼ˆæœ‹å‹çš„æœ‹å‹ï¼‰
    two_hop_neighbors = set()
    for n in neighbors:
        two_hop_neighbors.update(G.neighbors(n))
    two_hop_neighbors.discard(customer_id)
    n_two_hop = len(two_hop_neighbors)

    # 3. èŠ‚ç‚¹ä¸­å¿ƒæ€§
    degree centrality = nx.degree_centrality(G).get(customer_id, 0)
    betweenness = nx.betweenness_centrality(G).get(customer_id, 0)

    # 4. æ‰€åœ¨è¿é€šåˆ†é‡
    component_id = -1
    component_size = 0
    for i, component in enumerate(nx.connected_components(G)):
        if customer_id in component:
            component_id = i
            component_size = len(component)
            break

    # 5. èšç±»ç³»æ•°ï¼ˆè¡¡é‡é‚»å±…é—´çš„è¿æ¥ç´§å¯†ç¨‹åº¦ï¼‰
    clustering_coef = nx.clustering(G).get(customer_id, 0)

    return {
        'n_neighbors': n_neighbors,
        'n_two_hop_neighbors': n_two_hop,
        'degree_centrality': degree_centrality,
        'betweenness_centrality': betweenness,
        'component_size': component_size,
        'clustering_coefficient': clustering_coef,
    }
```

### 14.2.2 é£é™©ä¼ å¯¼ç‰¹å¾

```python
def risk_propagation_features(G, loans_df, target_customer):
    """
    è®¡ç®—é£é™©ä¼ å¯¼ç‰¹å¾
    åŸºäºé‚»å±…çš„è¿çº¦æƒ…å†µ
    """
    # æ„å»ºå®¢æˆ·è¿çº¦æ˜ å°„
    default_map = loans_df.set_index('customer_id')['isDefault'].to_dict()

    # ä¸€åº¦é‚»å±…è¿çº¦ç»Ÿè®¡
    neighbors = list(G.neighbors(target_customer))
    if not neighbors:
        return {'neighbor_default_rate': 0, 'neighbor_default_count': 0}

    neighbor_defaults = sum(default_map.get(n, 0) for n in neighbors)
    neighbor_default_rate = neighbor_defaults / len(neighbors)

    # åŠ æƒè¿çº¦ç‡ï¼ˆè€ƒè™‘å…³ç³»å¼ºåº¦ï¼‰
    weighted_defaults = 0
    total_weight = 0
    for n in neighbors:
        weight = G[target_customer][n].get('weight', 0.5)
        weighted_defaults += default_map.get(n, 0) * weight
        total_weight += weight

    weighted_default_rate = weighted_defaults / (total_weight + 1e-6)

    return {
        'neighbor_default_rate': neighbor_default_rate,
        'neighbor_default_count': neighbor_defaults,
        'weighted_neighbor_default_rate': weighted_default_rate,
        'n_good_neighbors': len(neighbors) - neighbor_defaults,
    }
```

---

## 14.3 å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰åŸºç¡€

### 14.3.1 å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰åŸç†

GCN çš„æ ¸å¿ƒæ€æƒ³ï¼š**èŠ‚ç‚¹çš„ç‰¹å¾é€šè¿‡é‚»å±…èšåˆè¿›è¡Œæ›´æ–°**ã€‚

```
æ•°å­¦å½¢å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰:
h_v^(l+1) = Ïƒ(Î£_{uâˆˆN(v)} W^(l) Â· h_u^(l) / |N(v)|)

å…¶ä¸­ï¼š
- h_v^(l): èŠ‚ç‚¹ v åœ¨ç¬¬ l å±‚çš„ç‰¹å¾
- N(v): v çš„é‚»å±…èŠ‚ç‚¹é›†åˆ
- W^(l): å¯å­¦ä¹ æƒé‡çŸ©é˜µ
- Ïƒ: æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLUï¼‰
```

**æ¶ˆæ¯ä¼ é€’æµç¨‹**ï¼š
1. **è¾“å…¥**ï¼šæ¯ä¸ªèŠ‚ç‚¹æœ‰åˆå§‹ç‰¹å¾å‘é‡ï¼ˆå¦‚ç”¨æˆ·å±æ€§ï¼‰
2. **èšåˆ**ï¼šä¸­å¿ƒèŠ‚ç‚¹ A èšåˆé‚»å±… Bã€Cã€D çš„ç‰¹å¾
3. **æ›´æ–°**ï¼šé€šè¿‡å¯å­¦ä¹ æƒé‡ W å’Œæ¿€æ´»å‡½æ•°Ïƒï¼Œç”Ÿæˆæ–°çš„èŠ‚ç‚¹åµŒå…¥
4. **è¾“å‡º**ï¼šæœ€ç»ˆçš„èŠ‚ç‚¹åµŒå…¥ç”¨äºé¢„æµ‹ï¼ˆå¦‚è¿çº¦æ¦‚ç‡ï¼‰

**å¤šå±‚ GCN çš„è¡¨è¾¾èƒ½åŠ›**ï¼š
- 1 å±‚ GCNï¼šèšåˆ 1 é˜¶é‚»å±…ä¿¡æ¯
- 2 å±‚ GCNï¼šèšåˆ 2 é˜¶é‚»å±…ä¿¡æ¯ï¼ˆæœ‹å‹çš„æœ‹å‹ï¼‰
- 3 å±‚ GCNï¼šèšåˆ 3 é˜¶é‚»å±…ä¿¡æ¯ï¼ˆé€šå¸¸ 2-3 å±‚å·²è¶³å¤Ÿï¼‰

### 14.3.2 ä½¿ç”¨ PyTorch Geometric å®ç° GCN

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data

class GCNForRisk(nn.Module):
    """
    ç”¨äºé£æ§çš„å›¾å·ç§¯ç½‘ç»œ
    """
    def __init__(self, num_node_features, hidden_dim=64, num_layers=2):
        super().__init__()

        layers = []
        # è¾“å…¥å±‚
        layers.append(GCNConv(num_node_features, hidden_dim))
        self.batch_norm1 = nn.BatchNorm1d(hidden_dim)

        # éšè—å±‚
        for i in range(num_layers - 1):
            layers.append(GCNConv(hidden_dim, hidden_dim))
            layers.append(nn.BatchNorm1d(hidden_dim))

        self.gcn_layers = nn.ModuleList(layers)

        # è¾“å‡ºå±‚
        self.classifier = nn.Linear(hidden_dim, 1)
        self.dropout = nn.Dropout(0.3)

    def forward(self, x, edge_index, edge_weight=None):
        """
        x: èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ (num_nodes, num_features)
        edge_index: è¾¹ç´¢å¼• (2, num_edges)
        edge_weight: è¾¹æƒé‡ (num_edges,)
        """
        h = x
        for i, layer in enumerate(self.gcn_layers):
            if isinstance(layer, GCNConv):
                h = layer(h, edge_index, edge_weight=edge_weight)
                if i < len(self.gcn_layers) - 1:  # æœ€åä¸€å±‚ä¸åŠ æ¿€æ´»
                    h = self.batch_norm1(h)
                    h = F.relu(h)
                    h = self.dropout(h)
            else:
                h = layer(h)
                h = F.relu(h)
                h = self.dropout(h)

        # è¾“å‡ºè¿çº¦æ¦‚ç‡
        out = torch.sigmoid(self.classifier(h))
        return out.squeeze()


# æ•°æ®å‡†å¤‡ç¤ºä¾‹
def prepare_graph_data(loans_df, relations_df, node_features_df):
    """
    å‡†å¤‡å›¾ç¥ç»ç½‘ç»œè¾“å…¥æ•°æ®
    """
    # åˆ›å»º customer_id åˆ°ç´¢å¼•çš„æ˜ å°„
    customers = loans_df['customer_id'].unique()
    id_to_idx = {c: i for i, c in enumerate(customers)}

    # èŠ‚ç‚¹ç‰¹å¾
    node_features = torch.FloatTensor(
        node_features_df.loc[customers].fillna(0).values
    )

    # è¾¹ç´¢å¼•
    edge_list = []
    edge_weights = []
    for _, row in relations_df.iterrows():
        if row['customer_id_1'] in id_to_idx and row['customer_id_2'] in id_to_idx:
            edge_list.append([
                id_to_idx[row['customer_id_1']],
                id_to_idx[row['customer_id_2']]
            ])
            edge_weights.append(0.8)  # æ— å‘å›¾ï¼ŒåŒå‘æ·»åŠ 
            edge_list.append([
                id_to_idx[row['customer_id_2']],
                id_to_idx[row['customer_id_1']]
            ])
            edge_weights.append(0.8)

    edge_index = torch.LongTensor(edge_list).t()  # (2, num_edges)
    edge_weight = torch.FloatTensor(edge_weights)

    # æ ‡ç­¾
    y = torch.FloatTensor(loans_df.set_index('customer_id').loc[customers]['isDefault'].values)

    # æ„å»º PyG Data
    data = Data(x=node_features, edge_index=edge_index,
                edge_weight=edge_weight, y=y)

    return data, customers, id_to_idx
```

### 14.3.3 GraphSAGEï¼šé€‚ç”¨äºå¤§å›¾çš„é‡‡æ ·æ–¹æ³•

```python
from torch_geometric.nn import SAGEConv

class GraphSAGEForRisk(nn.Module):
    """
    GraphSAGEï¼šé€šè¿‡é‚»å±…é‡‡æ ·è¿›è¡Œå½’çº³å¼å­¦ä¹ 
    é€‚åˆå¤§è§„æ¨¡å›¾ï¼ˆæ— æ³•ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜ï¼‰
    """
    def __init__(self, num_node_features, hidden_dim=128, num_layers=3):
        super().__init__()

        self.convs = nn.ModuleList()
        self.convs.append(SAGEConv(num_node_features, hidden_dim))

        for i in range(num_layers - 1):
            self.convs.append(SAGEConv(hidden_dim, hidden_dim))

        self.classifier = nn.Linear(hidden_dim, 1)
        self.dropout = nn.Dropout(0.3)

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < len(self.convs) - 1:
                x = F.relu(x)
                x = self.dropout(x)

        out = torch.sigmoid(self.classifier(x))
        return out.squeeze()


# ä½¿ç”¨é‚»å±…é‡‡æ ·è¿›è¡Œå°æ‰¹é‡è®­ç»ƒ
from torch_geometric.loader import NeighborLoader

def create_neighbor_loader(data, batch_size=256, num_neighbors=[10, 5]):
    """
    é‚»å±…é‡‡æ · DataLoader
    num_neighbors: æ¯å±‚é‡‡æ ·çš„é‚»å±…æ•°
    """
    loader = NeighborLoader(
        data,
        num_neighbors=num_neighbors,  # ä¸€é˜¶é‡‡æ · 10 ä¸ªï¼ŒäºŒé˜¶é‡‡æ · 5 ä¸ª
        batch_size=batch_size,
        shuffle=True,
        input_nodes=torch.arange(data.num_nodes),
    )
    return loader
```

---

## 14.4 å›¾æ¨¡å‹åœ¨åæ¬ºè¯ˆä¸­çš„åº”ç”¨

### 14.4.1 æ¬ºè¯ˆå›¢ä¼™æ£€æµ‹

```python
import networkx as nx
from community import community_louvain

def detect_fraud_rings(G, resolution=1.0):
    """
    ä½¿ç”¨ Louvain ç®—æ³•æ£€æµ‹æ¬ºè¯ˆå›¢ä¼™
    resolution: åˆ†è¾¨ç‡å‚æ•°ï¼Œè¶Šå¤§ç¤¾åŒºè¶Šå°
    """
    # Louvain ç¤¾åŒºæ£€æµ‹
    partition = community_louvain.best_partition(G, resolution=resolution)

    # åˆ†ææ¯ä¸ªç¤¾åŒºçš„é£é™©
    community_risk = {}
    for node, comm_id in partition.items():
        if comm_id not in community_risk:
            community_risk[comm_id] = {'nodes': [], 'default_count': 0}
        community_risk[comm_id]['nodes'].append(node)

    # è®¡ç®—æ¯ä¸ªç¤¾åŒºçš„è¿çº¦ç‡
    for comm_id, info in community_risk.items():
        # è¿™é‡Œéœ€è¦å®é™…çš„è¿çº¦æ ‡ç­¾
        # default_count = sum(1 for n in info['nodes'] if has_default_label(n))
        # info['default_rate'] = default_count / len(info['nodes'])
        pass

    # è¯†åˆ«é«˜é£é™©ç¤¾åŒºï¼ˆè¿çº¦ç‡é«˜ä¸”èŠ‚ç‚¹æ•°é€‚ä¸­ï¼‰
    high_risk_communities = [
        comm_id for comm_id, info in community_risk.items()
        if len(info['nodes']) >= 3  # è‡³å°‘ 3 ä¸ªèŠ‚ç‚¹
        # and info['default_rate'] > 0.3  # è¿çº¦ç‡è¶…è¿‡ 30%
    ]

    return partition, high_risk_communities
```

### 14.4.2 å¼‚å¸¸å­å›¾æ£€æµ‹

```python
def detect_anomalous_subgraphs(G, min_size=3, max_diameter=3):
    """
    æ£€æµ‹å¼‚å¸¸å­å›¾ï¼ˆå¯èƒ½æ˜¯æ¬ºè¯ˆå›¢ä¼™ï¼‰
    ç‰¹å¾ï¼š
    - å®Œå…¨å­å›¾ï¼ˆcliqueï¼‰ï¼šæ‰€æœ‰èŠ‚ç‚¹ä¸¤ä¸¤ç›¸è¿
    - é«˜å¯†åº¦å­å›¾ï¼šè¾¹æ•°æ¥è¿‘èŠ‚ç‚¹æ•°çš„å®Œå…¨å›¾
    """
    anomalous_subgraphs = []

    # æŸ¥æ‰¾æ‰€æœ‰å›¢ï¼ˆcliqueï¼‰
    cliques = list(nx.find_cliques(G))

    for clique in cliques:
        if len(clique) >= min_size:
            anomalous_subgraphs.append({
                'nodes': clique,
                'type': 'clique',
                'size': len(clique),
                'density': 1.0,  # å®Œå…¨å›¾å¯†åº¦ä¸º 1
            })

    # æŸ¥æ‰¾é«˜å¯†åº¦å­å›¾
    for component in nx.connected_components(G):
        subgraph = G.subgraph(component)
        if len(component) >= min_size:
            density = nx.density(subgraph)
            diameter = nx.diameter(subgraph) if nx.is_connected(subgraph) else -1

            if density > 0.5 and diameter <= max_diameter:
                anomalous_subgraphs.append({
                    'nodes': list(component),
                    'type': 'dense_subgraph',
                    'size': len(component),
                    'density': density,
                    'diameter': diameter,
                })

    return anomalous_subgraphs
```

---

## 14.5 å®æˆ˜ï¼šè®¾å¤‡å…³è”å›¾è°±

### 14.5.1 æ„å»ºè®¾å¤‡ - ç”¨æˆ·äºŒåˆ†å›¾

```python
import networkx as nx

def build_device_user_graph(loans_df, device_log_df):
    """
    æ„å»ºè®¾å¤‡ - ç”¨æˆ·äºŒåˆ†å›¾
    loans_df: å€Ÿæ¬¾è®°å½•ï¼ˆuser_id, loan_idï¼‰
    device_log_df: è®¾å¤‡æ—¥å¿—ï¼ˆuser_id, device_id, device_typeï¼‰
    """
    G = nx.Graph()

    # æ·»åŠ ç”¨æˆ·èŠ‚ç‚¹
    users = loans_df['user_id'].unique()
    for u in users:
        G.add_node(f'U_{u}', node_type='user', is_borrower=True)

    # æ·»åŠ è®¾å¤‡èŠ‚ç‚¹
    devices = device_log_df['device_id'].unique()
    for d in devices:
        device_info = device_log_df[device_log_df['device_id'] == d].iloc[0]
        G.add_node(
            f'D_{d}',
            node_type='device',
            device_type=device_info['device_type']
        )

    # æ·»åŠ ç”¨æˆ· - è®¾å¤‡è¾¹
    for _, row in device_log_df.iterrows():
        G.add_edge(
            f'U_{row["user_id"]}',
            f'D_{row["device_id"]}',
            weight=0.8
        )

    return G


def analyze_device_sharing(G):
    """
    åˆ†æè®¾å¤‡å…±äº«æƒ…å†µ
    """
    device_sharing_stats = {}

    for node, data in G.nodes(data=True):
        if data['node_type'] == 'user':
            neighbors = list(G.neighbors(node))
            device_neighbors = [
                n for n in neighbors
                if G.nodes[n]['node_type'] == 'device'
            ]

            # å…±äº«è®¾å¤‡æ•°ï¼ˆè¢«å¤šä¸ªç”¨æˆ·ä½¿ç”¨çš„è®¾å¤‡ï¼‰
            shared_devices = 0
            for d in device_neighbors:
                device_users = [
                    n for n in G.neighbors(d)
                    if G.nodes[n]['node_type'] == 'user'
                ]
                if len(device_users) > 1:
                    shared_devices += 1

            device_sharing_stats[node] = {
                'n_devices': len(device_neighbors),
                'n_shared_devices': shared_devices,
                'shared_device_ratio': shared_devices / (len(device_neighbors) + 1e-6),
            }

    return device_sharing_stats
```

### 14.5.2 å›¾ç‰¹å¾åŠ å…¥æœºå™¨å­¦ä¹ æ¨¡å‹

```python
def integrate_graph_features_into_ml(X_train, G, customer_ids):
    """
    å°†å›¾ç‰¹å¾æ•´åˆåˆ°ä¼ ç»Ÿæœºå™¨å­¦ä¹ æµç¨‹
    """
    graph_features = []

    for customer_id in customer_ids:
        # æå–åŸºç¡€å›¾ç‰¹å¾
        feat = extract_graph_features(G, customer_id)

        # æå–é£é™©ä¼ å¯¼ç‰¹å¾
        risk_feat = risk_propagation_features(G, X_train, customer_id)

        # åˆå¹¶
        feat.update(risk_feat)
        graph_features.append(feat)

    # è½¬æ¢ä¸º DataFrame
    graph_df = pd.DataFrame(graph_features, index=customer_ids)

    # ä¸åŸå§‹ç‰¹å¾åˆå¹¶
    X_enhanced = pd.concat([X_train, graph_df], axis=1)

    return X_enhanced
```

---

## 14.6 å›¾æ¨¡å‹çš„æŒ‘æˆ˜ä¸æ³¨æ„äº‹é¡¹

### 14.6.1 æ•°æ®éšç§ä¸åˆè§„

```markdown
âš ï¸ å›¾æ¨¡å‹ä½¿ç”¨çš„åˆè§„æ³¨æ„äº‹é¡¹ï¼š

1. æ•°æ®æ¥æºåˆæ³•æ€§
   - ç”¨æˆ·å…³ç³»æ•°æ®éœ€ç»ç”¨æˆ·æˆæƒ
   - ä¸å¾—éæ³•è·å–é€šè®¯å½•ç­‰éšç§æ•°æ®

2. å…³è”å…³ç³»çš„ä½¿ç”¨è¾¹ç•Œ
   - ä¸å¾—å› "å…³è”äººè¿çº¦"ç›´æ¥æ‹’ç»å®¢æˆ·
   - å›¾ç‰¹å¾åªèƒ½ä½œä¸ºé£é™©å‚è€ƒä¿¡å·

3. ç›‘ç®¡è¦æ±‚
   - éœ€å‘ç›‘ç®¡è¯´æ˜å›¾æ¨¡å‹çš„ä½¿ç”¨é€»è¾‘
   - ä¿ç•™äººå·¥å¤æ ¸é€šé“
```

### 14.6.2 å›¾æ•°æ®çš„æ—¶é—´ä¸€è‡´æ€§

```python
def build_temporal_graph(loans_df, relations_df, observation_date):
    """
    æ„å»ºæ—¶åºä¸€è‡´çš„å›¾
    åªèƒ½ä½¿ç”¨è§‚å¯Ÿæ—¥ä¹‹å‰çš„å…³ç³»æ•°æ®
    """
    # è¿‡æ»¤ï¼šå…³ç³»å¿…é¡»åœ¨è§‚å¯Ÿæ—¥ä¹‹å‰å­˜åœ¨
    relations_before = relations_df[
        relations_df['relation_start_date'] <= observation_date
    ].copy()

    # è¿‡æ»¤ï¼šåªè€ƒè™‘åœ¨è§‚å¯Ÿæ—¥ä¹‹å‰çš„å€Ÿæ¬¾
    loans_before = loans_df[
        loans_df['loan_date'] <= observation_date
    ].copy()

    G = build_customer_graph(loans_before, relations_before)
    return G
```

---

> **æœ¬ç« å°ç»“**ï¼šå›¾æ¨¡å‹ä¸ºé£æ§æä¾›äº†å…³ç³»è§†è§’çš„é£é™©è¯†åˆ«èƒ½åŠ›ï¼Œç‰¹åˆ«é€‚åˆåæ¬ºè¯ˆåœºæ™¯ã€‚GCN å’Œ GraphSAGE æ˜¯ä¸»æµçš„å›¾ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œèƒ½å¤Ÿç«¯åˆ°ç«¯å­¦ä¹ èŠ‚ç‚¹è¡¨ç¤ºã€‚ä½¿ç”¨æ—¶éœ€æ³¨æ„æ•°æ®éšç§åˆè§„å’Œæ—¶åºä¸€è‡´æ€§é—®é¢˜ã€‚
